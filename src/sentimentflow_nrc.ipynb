{
 "cells": [
  {
   "cell_type": "code",
   "id": "56a06b0548df3456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T09:24:54.429349Z",
     "start_time": "2025-02-27T09:24:48.190884Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "Example usage of SentimentFlow with the expanded NRC lexicon.\n",
    "\"\"\"\n",
    "\n",
    "from nrclex import NRCLex\n",
    "from ExpandNRC import EmotionDistanceCalculator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use local lexicon json for updated version of NRC\n",
    "feelings_nrc = NRCLex(\"/Users/Panos/Library/CloudStorage/Dropbox/PI_Squared/PycharmProjects/Research/NRCLex/nrc_v3.json\")\n",
    "emotion_lexicon = feelings_nrc.__lexicon__\n",
    "\n",
    "# Initialize the calculator (using CPU for simplicity)\n",
    "calculator = EmotionDistanceCalculator(emotion_lexicon, device=\"cpu\")\n",
    "\n",
    "# Demonstration: get emotions for single words and a batch\n",
    "result_single = calculator.get_emotions(\"happy\")\n",
    "print(\"Emotions for 'happy':\", result_single)\n",
    "\n",
    "result_batch = calculator.get_emotions([\"happy\", \"sad\", \"morning\"])\n",
    "print(\"Emotions for batch:\", result_batch)\n",
    "\n",
    "nrc_emotions = calculator.nrc_emotions([\"happy\", \"sad\", \"morning\"])\n",
    "print(\"NRC emotions:\", nrc_emotions)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached embeddings for 4566 words from /Users/Panos/.cache/ExpandNRC/lexicon_embeddings_cache.pkl\n",
      "Emotions for 'happy': {'happy': {'anticipation': np.float64(1.0), 'joy': np.float64(1.0), 'trust': np.float64(1.0)}}\n",
      "Emotions for batch: {'happy': {'anticipation': np.float64(1.0), 'joy': np.float64(1.0), 'trust': np.float64(1.0)}, 'sad': {'fear': np.float64(0.5472803863453726), 'sadness': np.float64(0.6876299497867969)}, 'morning': {'neutral': np.float64(0.5074773250951323)}}\n",
      "NRC emotions: {'happy': ['anticipation', 'joy', 'trust'], 'sad': ['fear', 'sadness'], 'morning': ['neutral']}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-27T10:13:57.155531Z",
     "start_time": "2025-02-27T09:38:29.349496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Helper function to extract a numeric value from a value\n",
    "def get_numeric_value(val):\n",
    "    if isinstance(val, (int, float)):\n",
    "        return val\n",
    "    elif isinstance(val, dict):\n",
    "        # Sum numeric values within the nested dictionary\n",
    "        total = 0\n",
    "        for sub_val in val.values():\n",
    "            if isinstance(sub_val, (int, float)):\n",
    "                total += sub_val\n",
    "        return total\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# Function to aggregate emotion dictionaries.\n",
    "def aggregate_emotions(emotion_results):\n",
    "    aggregated = {}\n",
    "    for emo in emotion_results:\n",
    "        if isinstance(emo, dict):\n",
    "            for key, value in emo.items():\n",
    "                # Use our helper to get a numeric value for each emotion\n",
    "                aggregated[key] = aggregated.get(key, 0) + get_numeric_value(value)\n",
    "        else:\n",
    "            # Skip results that are not dictionaries\n",
    "            print(\"Warning: Expected dictionary, got:\", emo)\n",
    "    return aggregated\n",
    "\n",
    "# Function to compute a simple sentiment score from aggregated emotions.\n",
    "# Positive emotions: joy and trust; Negative emotions: anger, fear, sadness, disgust.\n",
    "def compute_sentiment(aggregated_emotions):\n",
    "    positive = aggregated_emotions.get(\"joy\", 0) + aggregated_emotions.get(\"trust\", 0)\n",
    "    negative = (aggregated_emotions.get(\"anger\", 0) +\n",
    "                aggregated_emotions.get(\"fear\", 0) +\n",
    "                aggregated_emotions.get(\"sadness\", 0) +\n",
    "                aggregated_emotions.get(\"disgust\", 0))\n",
    "    return positive - negative\n",
    "\n",
    "# Sample text to analyze\n",
    "sample_text = \"\"\"\n",
    "I am very happy today. The sun is shining and I feel full of energy.\n",
    "However, sometimes I feel a tinge of sadness when I think about the past.\n",
    "Overall, I trust that better days are coming.\n",
    "\"\"\"\n",
    "\n",
    "# Split the sample text into sentences (a simple period-based split)\n",
    "sentences = [sentence.strip() for sentence in sample_text.split('.') if sentence.strip()]\n",
    "\n",
    "sentiment_scores = []\n",
    "for sentence in sentences:\n",
    "    # Split sentence into words (basic tokenization; consider using a more robust tokenizer)\n",
    "    words = sentence.split()\n",
    "    # Process each word individually to get its emotion score\n",
    "    word_emotions = [calculator.get_emotions(word) for word in words]\n",
    "    # Aggregate emotion scores for the entire sentence\n",
    "    agg_emotions = aggregate_emotions(word_emotions)\n",
    "    # Compute sentiment score for the sentence\n",
    "    score = compute_sentiment(agg_emotions)\n",
    "    sentiment_scores.append(score)\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Aggregated Emotions: {agg_emotions}\")\n",
    "    print(f\"Sentiment score: {score}\")\n",
    "\n",
    "# Plot the sentiment flow over sentences\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(sentiment_scores, marker='o')\n",
    "plt.title(\"Sentiment Flow\")\n",
    "plt.xlabel(\"Sentence Index\")\n",
    "plt.ylabel(\"Sentiment Score\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I am very happy today\n",
      "Aggregated Emotions: {'I': 0.5, 'am': 0.5, 'very': 0.5, 'happy': np.float64(3.0), 'today': 0.5}\n",
      "Sentiment score: 0\n",
      "Sentence: The sun is shining and I feel full of energy\n",
      "Aggregated Emotions: {'The': np.float64(1.5787563877728714), 'sun': np.float64(2.557617025706988), 'is': 0.5, 'shining': np.float64(4.619284115727158), 'and': 0.5, 'I': 0.5, 'feel': np.float64(1.0), 'full': np.float64(0.5788951832837793), 'of': 0.5, 'energy': 0.5}\n",
      "Sentiment score: 0\n",
      "Sentence: However, sometimes I feel a tinge of sadness when I think about the past\n",
      "Aggregated Emotions: {'However,': 0.5, 'sometimes': 0.5, 'I': 1.0, 'feel': np.float64(1.0), 'a': 0.5, 'tinge': 0.5, 'of': 0.5, 'sadness': np.float64(3.5112136562423255), 'when': 0.5, 'think': np.float64(1.5090485987139286), 'about': 0.5, 'the': np.float64(1.5787563877728714), 'past': 0.5}\n",
      "Sentiment score: -3.5112136562423255\n",
      "Sentence: Overall, I trust that better days are coming\n",
      "Aggregated Emotions: {'Overall,': 0.5, 'I': 0.5, 'trust': np.float64(1.0), 'that': 0.5, 'better': np.float64(3.3477977423855707), 'days': np.float64(0.5047502128545808), 'are': 0.5, 'coming': np.float64(2.0)}\n",
      "Sentiment score: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "KeyboardInterrupt                         Traceback (most recent call last)",
      "Cell In[6], line 70\n     68 plt.ylabel(\"Sentiment Score\")\n     69 plt.grid(True)\n---> 70 plt.show()\n",
      "File ~/Library/Caches/pypoetry/virtualenvs/sf-CO32cQqZ-py3.12/lib/python3.12/site-packages/matplotlib/pyplot.py:614, in show(*args, **kwargs)\n    570 \"\"\"\n    571 Display all open figures.\n    572 \n   (...)\n    611 explicitly there.\n    612 \"\"\"\n    613 _warn_if_gui_out_of_main_thread()\n--> 614 return _get_backend_mod().show(*args, **kwargs)\n",
      "File ~/Library/Caches/pypoetry/virtualenvs/sf-CO32cQqZ-py3.12/lib/python3.12/site-packages/matplotlib/backend_bases.py:3547, in _Backend.show(cls, block)\n   3545     block = not ipython_pylab and not is_interactive()\n   3546 if block:\n-> 3547     cls.mainloop()\n",
      "File ~/Library/Caches/pypoetry/virtualenvs/sf-CO32cQqZ-py3.12/lib/python3.12/site-packages/matplotlib/backends/backend_macosx.py:179, in FigureManagerMac.start_main_loop(cls)\n    176 @classmethod\n    177 def start_main_loop(cls):\n    178     # Set up a SIGINT handler to allow terminating a plot via CTRL-C.\n--> 179     with _allow_interrupt_macos():\n    180         _macosx.show()\n",
      "File /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:144, in _GeneratorContextManager.__exit__(self, typ, value, traceback)\n    142 if typ is None:\n    143     try:\n--> 144         next(self.gen)\n    145     except StopIteration:\n    146         return False\n",
      "File ~/Library/Caches/pypoetry/virtualenvs/sf-CO32cQqZ-py3.12/lib/python3.12/site-packages/matplotlib/backend_bases.py:1658, in _allow_interrupt(prepare_notifier, handle_sigint)\n   1656 signal.signal(signal.SIGINT, old_sigint_handler)\n   1657 if handler_args is not None:\n-> 1658     old_sigint_handler(*handler_args)\n",
      "KeyboardInterrupt: "
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T10:20:55.063746Z",
     "start_time": "2025-02-27T10:20:54.695178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from SentimentFlow import SpeechProcessor\n",
    "feelings_nrc = NRCLex(\"/Users/Panos/Library/CloudStorage/Dropbox/PI_Squared/PycharmProjects/Research/NRCLex/nrc_v3.json\")\n",
    "processor = SpeechProcessor(\"../data/senticnet.tsv\")"
   ],
   "id": "87bfe2137ba25600",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T10:22:00.895477Z",
     "start_time": "2025-02-27T10:21:52.535226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Comparison: Lexicon evolution (using nrc_emotions) vs. SentimentFlow simulation evolution.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# --- Setup for Lexicon Analysis using ExpandNRC ---\n",
    "from nrclex import NRCLex\n",
    "from ExpandNRC import EmotionDistanceCalculator\n",
    "\n",
    "# Load the updated NRC lexicon JSON (update the path as needed)\n",
    "feelings_nrc = NRCLex(\"/Users/Panos/Library/CloudStorage/Dropbox/PI_Squared/PycharmProjects/Research/NRCLex/nrc_v3.json\")\n",
    "emotion_lexicon = feelings_nrc.__lexicon__\n",
    "\n",
    "# Initialize the calculator (using CPU)\n",
    "calculator = EmotionDistanceCalculator(emotion_lexicon, device=\"cpu\")\n",
    "\n",
    "# We'll use the nrc_emotions() method so that we get only the emotion labels.\n",
    "# Define the standard NRC emotions (you can adjust this list as needed)\n",
    "nrc_emotions_list = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\"]\n",
    "\n",
    "# --- Lexicon-based Evolution: Split text into sentences and, for each sentence,\n",
    "# use nrc_emotions on its words to produce a binary indicator per emotion:\n",
    "# 0 if at least one word in the sentence has that emotion, 1 otherwise.\n",
    "sample_text = (\n",
    "    \"I am very happy today. The sun is shining and I feel full of energy. \"\n",
    "    \"However, sometimes I feel a tinge of sadness when I think about the past. \"\n",
    "    \"Overall, I trust that better days are coming.\"\n",
    ")\n",
    "sentences = [s.strip() for s in sample_text.split('.') if s.strip()]\n",
    "\n",
    "# For each sentence, produce a dictionary: {emotion: 0 (if present) or 1 (if absent)}\n",
    "lexicon_evolution = {emo: [] for emo in nrc_emotions_list}\n",
    "for sentence in sentences:\n",
    "    words = sentence.split()  # basic tokenization\n",
    "    # nrc_emotions() expects a list of words; assume it returns a list of lists,\n",
    "    # one per word, each being the set of emotions detected.\n",
    "    word_emotions = calculator.nrc_emotions(words)\n",
    "    # For each NRC emotion, set value 0 if at least one word has that emotion; else 1.\n",
    "    for emo in nrc_emotions_list:\n",
    "        present = any( (isinstance(em_list, list) and emo in em_list) for em_list in word_emotions )\n",
    "        lexicon_evolution[emo].append(0 if present else 1)\n",
    "\n",
    "# --- Setup for SentimentFlow Simulation ---\n",
    "# We use the SentimentFlow package components.\n",
    "from SentimentFlow import SpeechProcessor, SentimentFlowCalculator\n",
    "\n",
    "# Process the text with SenticNet-based SpeechProcessor.\n",
    "# (Update the path to your SenticNet data file as needed.)\n",
    "processor = SpeechProcessor(\"../data/senticnet.tsv\")\n",
    "df_text = pd.DataFrame({\"text\": [sample_text]})\n",
    "processed_texts = processor.process_texts(df_text[\"text\"])\n",
    "\n",
    "# For simulation, we work with the first (and only) processed text.\n",
    "processed_row = processed_texts.iloc[0]\n",
    "# Assume all columns except 'text' hold the baseline emotional values.\n",
    "sentiment_columns = processed_texts.columns.difference([\"text\"])\n",
    "s0 = processed_row[sentiment_columns].to_numpy(dtype=float)\n",
    "\n",
    "# We'll define a mapping between NRC emotions and the SenticNet dimensions.\n",
    "nrc_to_sentic = {\n",
    "    \"joy\": \"INTROSPECTION#joy\",\n",
    "    \"anger\": \"ATTITUDE#annoyance\",\n",
    "    \"disgust\": \"SENSITIVITY#loathing\",\n",
    "    \"anticipation\": \"SENSITIVITY#enthusiasm\",\n",
    "    \"surprise\": \"TEMPER#serenity\",\n",
    "    \"sadness\": \"INTROSPECTION#ecstasy\",\n",
    "    \"fear\": \"POLARITY\",      # arbitrary mapping\n",
    "    \"trust\": \"ATTITUDE\"      # arbitrary mapping\n",
    "}\n",
    "\n",
    "# Find indices in the baseline vector corresponding to each mapped dimension.\n",
    "sentic_columns = list(sentiment_columns)\n",
    "mapped_indices = {}\n",
    "for emo, col in nrc_to_sentic.items():\n",
    "    if col in sentic_columns:\n",
    "        mapped_indices[emo] = sentic_columns.index(col)\n",
    "    else:\n",
    "        print(f\"Warning: {col} not found in processed features.\")\n",
    "\n",
    "# Prepare the simulation using SentimentFlowCalculator methods.\n",
    "sf_calc = SentimentFlowCalculator()\n",
    "\n",
    "# Compute the external contextual force from POLARITY.\n",
    "g_context = SentimentFlowCalculator._calculate_external_contextual_force(processed_row[\"POLARITY\"])\n",
    "# Compute sentiment density, pressure, and viscosity from s0.\n",
    "rho_sent = SentimentFlowCalculator._calculate_sentiment_density(s0)\n",
    "# For pressure, the original code applies the _calculate_sentiment_pressure to each component.\n",
    "p_sent = np.array([sf_calc._calculate_sentiment_pressure(score, processed_row[\"text\"]) for score in s0])\n",
    "nu_sent = SentimentFlowCalculator._calculate_sentiment_viscosity(s0)\n",
    "speech_info = (rho_sent, p_sent, nu_sent, g_context)\n",
    "\n",
    "# Increase simulation steps by integrating over a longer time.\n",
    "# For example, simulate from t=0 to t=10 with 11 steps.\n",
    "t = np.linspace(0, 10, 11)\n",
    "s_simulation = odeint(SentimentFlowCalculator._differential_equation, s0, t, args=(speech_info,))\n",
    "\n",
    "# For each mapped NRC emotion, extract its simulation evolution.\n",
    "simulation_evolution = {}\n",
    "for emo, idx in mapped_indices.items():\n",
    "    simulation_evolution[emo] = s_simulation[:, idx]\n",
    "\n",
    "# --- Plotting ---\n",
    "# For each NRC emotion in our list, if it is mapped, plot two curves:\n",
    "# 1. Lexicon evolution over sentences (x-axis: sentence index; y: binary value)\n",
    "# 2. Simulation evolution over time (x-axis: simulation time; y: simulated value)\n",
    "for emo in nrc_emotions_list:\n",
    "    if emo in mapped_indices:\n",
    "        fig, ax = plt.subplots(2, 1, figsize=(8, 6), sharex=False)\n",
    "        # Plot lexicon evolution (discrete per sentence)\n",
    "        ax[0].plot(range(len(sentences)), lexicon_evolution[emo], marker='o', linestyle='--', color='blue')\n",
    "        ax[0].set_title(f\"Lexicon-based Evolution for NRC '{emo}'\")\n",
    "        ax[0].set_xlabel(\"Sentence Index\")\n",
    "        ax[0].set_ylabel(\"Binary Indicator (0 = Present)\")\n",
    "        ax[0].set_ylim(-0.5, 1.5)\n",
    "        ax[0].set_xticks(range(len(sentences)))\n",
    "        # Plot simulation evolution for the mapped baseline dimension\n",
    "        ax[1].plot(t, simulation_evolution[emo], marker='x', linestyle='-', color='red')\n",
    "        ax[1].set_title(f\"SentimentFlow Simulation for '{nrc_to_sentic[emo]}' (mapped from NRC '{emo}')\")\n",
    "        ax[1].set_xlabel(\"Time Step\")\n",
    "        ax[1].set_ylabel(\"Simulated Value\")\n",
    "        ax[1].grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Skipping NRC emotion '{emo}' because it is not mapped to a SenticNet dimension.\")"
   ],
   "id": "86e1fa0f120e57d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached embeddings for 4566 words from /Users/Panos/.cache/ExpandNRC/lexicon_embeddings_cache.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-Feb-25 11:21:54 - Starting to process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Processing texts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c836b6b621db4ef6b18deef6d2a685dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-Feb-25 11:21:55 - Saving results to results/processed_texts.csv\n",
      "/var/folders/2_/dcqzbsq91y378h2r26m31x_h0000gn/T/ipykernel_37101/4059946640.py:99: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  s_simulation = odeint(SentimentFlowCalculator._differential_equation, s0, t, args=(speech_info,))\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T11:01:43.539093Z",
     "start_time": "2025-02-27T11:01:40.689385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "# Assumed predefined variables:\n",
    "# feelings_nrc = NRCLex(\"/Users/Panos/Library/CloudStorage/Dropbox/PI_Squared/PycharmProjects/Research/NRCLex/nrc_v3.json\")\n",
    "# processor = SpeechProcessor(\"../data/senticnet.tsv\")\n",
    "# And the ExpandNRC calculator is initialized as:\n",
    "calculator = EmotionDistanceCalculator(feelings_nrc.__lexicon__, device=\"cpu\")\n",
    "\n",
    "# ---------- Part 1: Lexicon Analysis Per Word ----------\n",
    "# Define the eight standard NRC emotions.\n",
    "nrc_emotions_list = [\"anger\", \"anticipation\", \"disgust\", \"fear\", \"joy\", \"sadness\", \"surprise\", \"trust\"]\n",
    "\n",
    "# Tokenize the sample text into words.\n",
    "sample_text = (\n",
    "    \"I am very happy today. The sun is shining and I feel full of energy. \"\n",
    "    \"However, sometimes I feel a tinge of sadness when I think about the past. \"\n",
    "    \"Overall, I trust that better days are coming.\"\n",
    ")\n",
    "words = sample_text.split()  # simple tokenization\n",
    "\n",
    "# For each word, obtain the NRC emotion labels using nrc_emotions.\n",
    "lexicon_results = []\n",
    "for word in words:\n",
    "    result = calculator.nrc_emotions([word], threshold=0.4)\n",
    "    # When passing a single word, assume the method returns a dict keyed by that word.\n",
    "    if isinstance(result, dict):\n",
    "        emotions = result.get(word, [])\n",
    "    elif isinstance(result, list):\n",
    "        emotions = result[0]\n",
    "    else:\n",
    "        emotions = []\n",
    "    lexicon_results.append(emotions)\n",
    "\n",
    "# Create binary indicator per word for each of the 8 NRC emotions.\n",
    "lexicon_indicators = {emo: [] for emo in nrc_emotions_list}\n",
    "for em_list in lexicon_results:\n",
    "    for emo in nrc_emotions_list:\n",
    "        lexicon_indicators[emo].append(1 if (isinstance(em_list, list) and emo in em_list) else 0)\n",
    "\n",
    "# ---------- Part 2: SenticNet/SentimentFlow Analysis of the Whole Text ----------\n",
    "# Process the whole text using the SpeechProcessor.\n",
    "df_text = pd.DataFrame({\"text\": [sample_text]})\n",
    "processed_texts = processor.process_texts(df_text[\"text\"])\n",
    "processed_row = processed_texts.iloc[0]\n",
    "\n",
    "# The baseline sentiment features (SenticNet dimensions) are in all columns except 'text'.\n",
    "sentiment_columns = processed_texts.columns.difference([\"text\"])\n",
    "# Create the initial state vector (s0) from the processed features.\n",
    "s0 = processed_row[sentiment_columns].to_numpy(dtype=float)\n",
    "\n",
    "# For simulation, use the SentimentFlowCalculatorâ€™s methods.\n",
    "from SentimentFlow import SentimentFlowCalculator\n",
    "sf_calc = SentimentFlowCalculator()\n",
    "\n",
    "# Compute external contextual force, sentiment density, pressure, and viscosity.\n",
    "g_context = SentimentFlowCalculator._calculate_external_contextual_force(processed_row[\"POLARITY\"])\n",
    "rho_sent = SentimentFlowCalculator._calculate_sentiment_density(s0)\n",
    "p_sent = np.array([sf_calc._calculate_sentiment_pressure(score, processed_row[\"text\"]) for score in s0])\n",
    "nu_sent = SentimentFlowCalculator._calculate_sentiment_viscosity(s0)\n",
    "speech_info = (rho_sent, p_sent, nu_sent, g_context)\n",
    "\n",
    "# Increase simulation time resolution to match the number of words.\n",
    "t = np.arange(len(words))\n",
    "s_simulation = odeint(SentimentFlowCalculator._differential_equation, s0, t, args=(speech_info,))\n",
    "\n",
    "# For readability, clip the simulation values.\n",
    "clip_min = -3\n",
    "clip_max = 4\n",
    "s_simulation_clipped = np.clip(s_simulation, clip_min, clip_max)\n",
    "\n",
    "# Get the list of SenticNet (sentiment flow) dimensions.\n",
    "sentic_columns = list(sentiment_columns)\n",
    "\n",
    "# ---------- Part 3: Plotting and Saving Each Plot ----------\n",
    "# Create the plots folder if it doesn't exist.\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "# For each lexicon emotion, create an individual plot.\n",
    "for emo in nrc_emotions_list:\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    x = range(len(words))  # x-axis: word index\n",
    "\n",
    "    # Plot lexicon binary indicator (blue solid line)\n",
    "    ax.plot(x, lexicon_indicators[emo], marker='o', linestyle='-', color='blue', label='Lexicon Indicator')\n",
    "\n",
    "    # Overlay all SenticNet simulation dimensions (red dashed lines)\n",
    "    for j, col in enumerate(sentic_columns):\n",
    "        ax.plot(x, s_simulation_clipped[:, j], marker='x', linestyle='--',\n",
    "                label=f\"SenticNet: {col}\")\n",
    "\n",
    "    ax.set_title(f\"Lexicon Emotion: '{emo}'\")\n",
    "    ax.set_xlabel(\"Word Index\")\n",
    "    ax.set_ylabel(\"Clipped Value\")\n",
    "    ax.legend(fontsize=8, loc=\"upper right\")\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save each plot in the \"plots\" folder, using the emotion as the filename.\n",
    "    filename = os.path.join(\"plots\", f\"{emo}.png\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close(fig)"
   ],
   "id": "841e8d4c1e109714",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded cached embeddings for 4566 words from /Users/Panos/.cache/ExpandNRC/lexicon_embeddings_cache.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-Feb-25 12:01:42 - Starting to process\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Processing texts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c726ff97139643229f0ef4f3518a9ddb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27-Feb-25 12:01:42 - Saving results to results/processed_texts.csv\n",
      "/var/folders/2_/dcqzbsq91y378h2r26m31x_h0000gn/T/ipykernel_37101/3982133789.py:68: ODEintWarning: Excess work done on this call (perhaps wrong Dfun type). Run with full_output = 1 to get quantitative information.\n",
      "  s_simulation = odeint(SentimentFlowCalculator._differential_equation, s0, t, args=(speech_info,))\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "498efa4486c285f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
