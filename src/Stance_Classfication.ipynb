{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fluid Dynamics-Inspired Emotional Analysis & Sentiment Flow for Argumentation Mining (AM)\n",
    "- Stance basesd Argument Mining Modeling Using NRC and SneticNet Emotion Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to use \"Emotional Analysis\" (NRC,SenticNet, SOCAL) to improve\n",
    "\n",
    "- Stance Claissfication\n",
    "- Fine-Grained Classifcation \n",
    "\n",
    "- https://aclanthology.org/J11-2001.pdf    (SO-CAL)\n",
    "- https://github.com/sfu-discourse-lab/SO-CAL\n",
    "- Original of SC \n",
    "    - https://www.cs.cornell.edu/home/llee/papers/sentiment.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "from SentimentFlow import SpeechProcessor\n",
    "from SentimentFlow import SentimentFlowCalculator\n",
    "#https://github.com.mcas.ms/dpicca/SentimentFlow\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider\n",
    "import ipywidgets as widgets\n",
    "import os\n",
    "import spacy\n",
    "from nrclex import NRCLex\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from nrclex import NRCLex\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argumentative Microtext Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we've done a extensive pre-processing on microtext to extract all layers of annotations. The focus is stance classifcation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../data/dfMT-PC_SA_CP_topicID_AduType.json\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 112 entries, 0 to 111\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   EDU        112 non-null    object\n",
      " 1   adu_type   112 non-null    object\n",
      " 2   topic_id   89 non-null     object\n",
      " 3   Relations  112 non-null    object\n",
      " 4   Label      112 non-null    object\n",
      " 5   STANCE     89 non-null     object\n",
      "dtypes: object(6)\n",
      "memory usage: 6.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDU</th>\n",
       "      <th>adu_type</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>Relations</th>\n",
       "      <th>Label</th>\n",
       "      <th>STANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Yes, it's annoying and cumbersome to separate your rubbish properly all the time., Three different bin bags stink away in the kitchen and have to be sorted into different wheelie bins., But still Germany produces way too much rubbish, and too many resources are lost when what actually should be separated and recycled is burnt., We Berliners should take the chance and become pioneers in waste separation!]</td>\n",
       "      <td>[opp, opp, pro, pro, pro]</td>\n",
       "      <td>waste_separation</td>\n",
       "      <td>[[a1, a5, reb], [a2, a1, sup], [a3, c1, und], [a4, c3, add]]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[One can hardly move in Friedrichshain or Neukölln these days without permanently scanning the ground for dog dirt., And when bad luck does strike and you step into one of the many 'land mines' you have to painstakingly scrape the remains off your soles., Higher fines are therefore the right measure against negligent, lazy or simply thoughtless dog owners., Of course, first they'd actually need to be caught in the act by public order officers,, but once they have to dig into their pockets, their laziness will sure vanish!]</td>\n",
       "      <td>[pro, pro, pro, opp, pro]</td>\n",
       "      <td>higher_dog_poo_fines</td>\n",
       "      <td>[[a1, a3, sup], [a2, a3, sup], [a4, a3, reb], [a5, c4, und]]</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Health insurance companies should not cover treatment in complementary medicine, unless the promised effect and its medical benefit have been concretely proven., Yet this very proof is lacking in most cases., Patients do often report relief of their complaints after such treatments., But as long as it is unclear as to how this works, the funds should rather be spent on therapies where one knows with certainty.]</td>\n",
       "      <td>[pro, opp, pro, opp, pro]</td>\n",
       "      <td>health_insurance_cover_complementary_medicine</td>\n",
       "      <td>[[a2, a1, reb], [a3, a2, reb], [a4, a1, reb], [a5, c4, und]]</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Of course there are a number of programmes in public broadcasting that are not worth the licencing fee,, and others, such as “Musikantenstadl” and soap operas, are only interesting to certain audiences., Nevertheless, everybody should contribute to the funding of the public broadcasters in equal measure,, for we need general and independent media., After all we want to get our view of the world neither through the lens of the government nor through that of rich media entrepreneurs.]</td>\n",
       "      <td>[opp, opp, pro, pro, pro]</td>\n",
       "      <td>public_broadcasting_fees_on_demand</td>\n",
       "      <td>[[a1, a3, reb], [a2, a3, reb], [a4, a3, sup], [a5, a4, sup]]</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Intelligence services must urgently be regulated more tightly by parliament;, this should be clear to everyone after the disclosures of Edward Snowden., Granted, those concern primarily the British and American intelligence services,, but the German services evidently do collaborate with them closely., Their tools, data and expertise have been used to keep us under surveillance for a long time.]</td>\n",
       "      <td>[pro, pro, opp, pro, pro]</td>\n",
       "      <td>stricter_regulation_of_intelligence_services</td>\n",
       "      <td>[[a2, a1, sup], [a3, c2, und], [a4, c3, und], [a5, a4, sup]]</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[The death penalty is a legal means that as such is not practicable in Germany., For one thing, inviolable human dignity is anchored in our constitution,, and furthermore no one may have the right to adjudicate upon the death of another human being., Even if many people think that a murderer has already decided on the life or death of another person,, this is precisely the crime that we should not repay with the same.]</td>\n",
       "      <td>[pro, pro, pro, opp, pro]</td>\n",
       "      <td>introduce_capital_punishment</td>\n",
       "      <td>[[a2, a1, sup], [a3, a1, sup], [a4, a1, reb], [a5, c4, und]]</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Dog dirt on the pavement requires my complete, ground-focused attention on my way to work., This results in a lack of alertness in the road traffic comparable to a minor offense of the traffic regulations., That's why causing such obstacles must to be more urgently punished., Dog owners may think that dog dirt is only a harmless secretion of an animal like any other., Yet then they misjudge its impact on road traffic.]</td>\n",
       "      <td>[pro, pro, pro, opp, pro]</td>\n",
       "      <td>higher_dog_poo_fines</td>\n",
       "      <td>[[a1, a2, sup], [a2, a3, sup], [a4, a3, reb], [a5, a4, reb]]</td>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Of course it would be nice and simple if after a fun night out with a party acquaintance you could simply take the 'morning-after pill' and feel at ease., But it's not that simple., Perhaps a new life was already created that night., I would kill it without further thought., That's why a visit to the doctor and professional advice should remain mandatory.]</td>\n",
       "      <td>[opp, pro, pro, pro, pro]</td>\n",
       "      <td>over_the_counter_morning_after_pill</td>\n",
       "      <td>[[a1, a5, reb], [a2, a1, reb], [a3, a2, sup], [a4, c3, add]]</td>\n",
       "      <td>[0, 0, 0, 0, 1]</td>\n",
       "      <td>con</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[It is unfair and unjustifiable that new tenants have to pay a much higher rent than previous residents., Clearly the landlord has to pay for some repairs before a new lease., But surely these costs could be covered by a minimal increase in rent over the course of the entire lease., All the more so as for an adequate profit the rental rate as compared to the base rent need not be raised for every new lease.]</td>\n",
       "      <td>[pro, opp, pro, pro]</td>\n",
       "      <td>cap_rent_increases</td>\n",
       "      <td>[[a2, a1, reb], [a3, c2, und], [a4, a1, sup]]</td>\n",
       "      <td>[1, 0, 0, 0]</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Alternative treatments should be subsidized in the same way as conventional treatments,, since both methods can lead to the prevention, mitigation or cure of an illness., Besides it should be in the interest of the health insurers to recognize alternative medicine as treatment,, since there is a chance of recovery., It doesn't matter after all that those who administer the treatment don't have 'doctor status'.]</td>\n",
       "      <td>[pro, pro, pro, pro, pro]</td>\n",
       "      <td>health_insurance_cover_complementary_medicine</td>\n",
       "      <td>[[a2, a1, sup], [a3, a1, sup], [a4, a3, sup], [a5, a1, sup]]</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "      <td>pro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                EDU  \\\n",
       "0                                                                                                                          [Yes, it's annoying and cumbersome to separate your rubbish properly all the time., Three different bin bags stink away in the kitchen and have to be sorted into different wheelie bins., But still Germany produces way too much rubbish, and too many resources are lost when what actually should be separated and recycled is burnt., We Berliners should take the chance and become pioneers in waste separation!]   \n",
       "1  [One can hardly move in Friedrichshain or Neukölln these days without permanently scanning the ground for dog dirt., And when bad luck does strike and you step into one of the many 'land mines' you have to painstakingly scrape the remains off your soles., Higher fines are therefore the right measure against negligent, lazy or simply thoughtless dog owners., Of course, first they'd actually need to be caught in the act by public order officers,, but once they have to dig into their pockets, their laziness will sure vanish!]   \n",
       "2                                                                                                                   [Health insurance companies should not cover treatment in complementary medicine, unless the promised effect and its medical benefit have been concretely proven., Yet this very proof is lacking in most cases., Patients do often report relief of their complaints after such treatments., But as long as it is unclear as to how this works, the funds should rather be spent on therapies where one knows with certainty.]   \n",
       "3                                          [Of course there are a number of programmes in public broadcasting that are not worth the licencing fee,, and others, such as “Musikantenstadl” and soap operas, are only interesting to certain audiences., Nevertheless, everybody should contribute to the funding of the public broadcasters in equal measure,, for we need general and independent media., After all we want to get our view of the world neither through the lens of the government nor through that of rich media entrepreneurs.]   \n",
       "4                                                                                                                                   [Intelligence services must urgently be regulated more tightly by parliament;, this should be clear to everyone after the disclosures of Edward Snowden., Granted, those concern primarily the British and American intelligence services,, but the German services evidently do collaborate with them closely., Their tools, data and expertise have been used to keep us under surveillance for a long time.]   \n",
       "5                                                                                                            [The death penalty is a legal means that as such is not practicable in Germany., For one thing, inviolable human dignity is anchored in our constitution,, and furthermore no one may have the right to adjudicate upon the death of another human being., Even if many people think that a murderer has already decided on the life or death of another person,, this is precisely the crime that we should not repay with the same.]   \n",
       "6                                                                                                           [Dog dirt on the pavement requires my complete, ground-focused attention on my way to work., This results in a lack of alertness in the road traffic comparable to a minor offense of the traffic regulations., That's why causing such obstacles must to be more urgently punished., Dog owners may think that dog dirt is only a harmless secretion of an animal like any other., Yet then they misjudge its impact on road traffic.]   \n",
       "7                                                                                                                                                                           [Of course it would be nice and simple if after a fun night out with a party acquaintance you could simply take the 'morning-after pill' and feel at ease., But it's not that simple., Perhaps a new life was already created that night., I would kill it without further thought., That's why a visit to the doctor and professional advice should remain mandatory.]   \n",
       "8                                                                                                                       [It is unfair and unjustifiable that new tenants have to pay a much higher rent than previous residents., Clearly the landlord has to pay for some repairs before a new lease., But surely these costs could be covered by a minimal increase in rent over the course of the entire lease., All the more so as for an adequate profit the rental rate as compared to the base rent need not be raised for every new lease.]   \n",
       "9                                                                                                                   [Alternative treatments should be subsidized in the same way as conventional treatments,, since both methods can lead to the prevention, mitigation or cure of an illness., Besides it should be in the interest of the health insurers to recognize alternative medicine as treatment,, since there is a chance of recovery., It doesn't matter after all that those who administer the treatment don't have 'doctor status'.]   \n",
       "\n",
       "                    adu_type                                       topic_id  \\\n",
       "0  [opp, opp, pro, pro, pro]                               waste_separation   \n",
       "1  [pro, pro, pro, opp, pro]                           higher_dog_poo_fines   \n",
       "2  [pro, opp, pro, opp, pro]  health_insurance_cover_complementary_medicine   \n",
       "3  [opp, opp, pro, pro, pro]             public_broadcasting_fees_on_demand   \n",
       "4  [pro, pro, opp, pro, pro]   stricter_regulation_of_intelligence_services   \n",
       "5  [pro, pro, pro, opp, pro]                   introduce_capital_punishment   \n",
       "6  [pro, pro, pro, opp, pro]                           higher_dog_poo_fines   \n",
       "7  [opp, pro, pro, pro, pro]            over_the_counter_morning_after_pill   \n",
       "8       [pro, opp, pro, pro]                             cap_rent_increases   \n",
       "9  [pro, pro, pro, pro, pro]  health_insurance_cover_complementary_medicine   \n",
       "\n",
       "                                                      Relations  \\\n",
       "0  [[a1, a5, reb], [a2, a1, sup], [a3, c1, und], [a4, c3, add]]   \n",
       "1  [[a1, a3, sup], [a2, a3, sup], [a4, a3, reb], [a5, c4, und]]   \n",
       "2  [[a2, a1, reb], [a3, a2, reb], [a4, a1, reb], [a5, c4, und]]   \n",
       "3  [[a1, a3, reb], [a2, a3, reb], [a4, a3, sup], [a5, a4, sup]]   \n",
       "4  [[a2, a1, sup], [a3, c2, und], [a4, c3, und], [a5, a4, sup]]   \n",
       "5  [[a2, a1, sup], [a3, a1, sup], [a4, a1, reb], [a5, c4, und]]   \n",
       "6  [[a1, a2, sup], [a2, a3, sup], [a4, a3, reb], [a5, a4, reb]]   \n",
       "7  [[a1, a5, reb], [a2, a1, reb], [a3, a2, sup], [a4, c3, add]]   \n",
       "8                 [[a2, a1, reb], [a3, c2, und], [a4, a1, sup]]   \n",
       "9  [[a2, a1, sup], [a3, a1, sup], [a4, a3, sup], [a5, a1, sup]]   \n",
       "\n",
       "             Label STANCE  \n",
       "0  [0, 0, 0, 0, 1]    pro  \n",
       "1  [0, 0, 1, 0, 0]    pro  \n",
       "2  [1, 0, 0, 0, 0]    con  \n",
       "3  [0, 0, 1, 0, 0]    con  \n",
       "4  [1, 0, 0, 0, 0]    pro  \n",
       "5  [1, 0, 0, 0, 0]    con  \n",
       "6  [0, 0, 1, 0, 0]    pro  \n",
       "7  [0, 0, 0, 0, 1]    con  \n",
       "8     [1, 0, 0, 0]    pro  \n",
       "9  [1, 0, 0, 0, 0]    pro  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:10]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-NRC for emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nrc(text):\n",
    "    \"\"\"Calculate NRC sentiment frequencies for a given text.\"\"\"\n",
    "    if isinstance(text, list):  \n",
    "        text = \" \".join(text) \n",
    "    if not isinstance(text, str): \n",
    "        raise ValueError(f\"Expected string input, but got {type(text)}\")  \n",
    "    nrc_sentiment = NRCLex(text)  \n",
    "    return nrc_sentiment.affect_frequencies\n",
    "#nrc_sentiment.raw_emotion_scores,  nrc_sentiment.top_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Yes, it's annoying and cumbersome to separate your rubbish properly all the time.\", 'Three different bin bags stink away in the kitchen and have to be sorted into different wheelie bins.', 'But still Germany produces way too much rubbish', 'and too many resources are lost when what actually should be separated and recycled is burnt.', 'We Berliners should take the chance and become pioneers in waste separation!'] \n",
      " ['opp', 'opp', 'pro', 'pro', 'pro']\n"
     ]
    }
   ],
   "source": [
    "print(df.EDU[0],\"\\n\", df.adu_type[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fear': 0.0,\n",
       " 'anger': 0.14285714285714285,\n",
       " 'anticip': 0.0,\n",
       " 'trust': 0.0,\n",
       " 'surprise': 0.0,\n",
       " 'positive': 0.0,\n",
       " 'negative': 0.42857142857142855,\n",
       " 'sadness': 0.14285714285714285,\n",
       " 'disgust': 0.14285714285714285,\n",
       " 'joy': 0.0,\n",
       " 'anticipation': 0.14285714285714285}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_nrc(df.EDU[0][0])#which feaure are usefull for stance classfication= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nrc(text):\n",
    "    \"\"\"Calculate NRC sentiment frequencies for a given text.\"\"\"\n",
    "    if isinstance(text, list):  \n",
    "        text = \" \".join(text) \n",
    "    if not isinstance(text, str): \n",
    "        raise ValueError(f\"Expected string input, but got {type(text)}\")  \n",
    "    nrc_sentiment = NRCLex(text)  \n",
    "    return nrc_sentiment.affect_frequencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "coloraxis": "coloraxis",
         "hovertemplate": "ADU Type: %{x}<br>NRC Dimension: %{y}<br>Intensity: %{z}<extra></extra>",
         "name": "0",
         "type": "heatmap",
         "x": [
          "opp",
          "pro"
         ],
         "xaxis": "x",
         "y": [
          "fear",
          "anger",
          "trust",
          "surprise",
          "positive",
          "negative",
          "sadness",
          "disgust",
          "joy",
          "anticipation"
         ],
         "yaxis": "y",
         "z": [
          [
           0.05363416149068322,
           0.059281543372452464
          ],
          [
           0.04004051069703244,
           0.031034270197241372
          ],
          [
           0.12389385783298826,
           0.1338158054067145
          ],
          [
           0.024877984817115253,
           0.03162533348231796
          ],
          [
           0.24262084195997238,
           0.19456268048285785
          ],
          [
           0.15677066942719117,
           0.10881119270808849
          ],
          [
           0.06331987577639751,
           0.035101161874997795
          ],
          [
           0.041490890269151134,
           0.0336529119234219
          ],
          [
           0.036885714285714286,
           0.03675457641643894
          ],
          [
           0.06446549344375431,
           0.08924079021085674
          ]
         ]
        }
       ],
       "layout": {
        "coloraxis": {
         "colorbar": {
          "title": {
           "text": "Intensity"
          }
         },
         "colorscale": [
          [
           0,
           "rgb(103,0,31)"
          ],
          [
           0.1,
           "rgb(178,24,43)"
          ],
          [
           0.2,
           "rgb(214,96,77)"
          ],
          [
           0.3,
           "rgb(244,165,130)"
          ],
          [
           0.4,
           "rgb(253,219,199)"
          ],
          [
           0.5,
           "rgb(247,247,247)"
          ],
          [
           0.6,
           "rgb(209,229,240)"
          ],
          [
           0.7,
           "rgb(146,197,222)"
          ],
          [
           0.8,
           "rgb(67,147,195)"
          ],
          [
           0.9,
           "rgb(33,102,172)"
          ],
          [
           1,
           "rgb(5,48,97)"
          ]
         ]
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "NRC Emotion Intensity by ADU Type"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "ADU Type"
         }
        },
        "yaxis": {
         "anchor": "x",
         "autorange": "reversed",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "NRC Emotion Dimension"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calculate_nrc(text):\n",
    "    \"\"\"Calculate NRC emotion frequencies for a given text.\"\"\"\n",
    "    nrc_sentiment = NRCLex(text)\n",
    "    affect_dict = nrc_sentiment.affect_frequencies\n",
    "\n",
    "    base_emotions = ['fear', 'anger', 'trust', 'surprise', \n",
    "                     'positive', 'negative', 'sadness', 'disgust', 'joy', \"anticipation\"]\n",
    "    \n",
    "    for emotion in base_emotions:\n",
    "        if emotion not in affect_dict:\n",
    "            affect_dict[emotion] = 0.0\n",
    "\n",
    "    return {emotion: affect_dict[emotion] for emotion in base_emotions}\n",
    "\n",
    "def process_data(df):\n",
    "    \"\"\"Process DataFrame by applying NRC analysis and filtering emotions.\"\"\"\n",
    "    df_exp = df.explode(['EDU', 'adu_type'])\n",
    "    \n",
    "    nrc_features = df_exp['EDU'].apply(lambda x: pd.Series(calculate_nrc(x)))\n",
    "    \n",
    "    return pd.concat([df_exp[['adu_type']], nrc_features], axis=1)\n",
    "\n",
    "def visualize_correlation(processed_df):\n",
    "    \"\"\"Generate a heatmap visualization of NRC emotions by ADU type.\"\"\"\n",
    "    grouped = processed_df.groupby('adu_type').mean().reset_index()\n",
    "    \n",
    "    melted = grouped.melt(id_vars='adu_type', \n",
    "                          var_name='Emotion', \n",
    "                          value_name='Intensity')\n",
    "\n",
    "    fig = px.imshow(\n",
    "        grouped.set_index('adu_type').T,\n",
    "        labels=dict(x=\"ADU Type\", y=\"NRC Dimension\", color=\"Intensity\"),\n",
    "        color_continuous_scale='RdBu',\n",
    "        title=\"NRC Emotion Intensity by ADU Type\",\n",
    "        aspect=\"auto\"\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"ADU Type\",\n",
    "        yaxis_title=\"NRC Emotion Dimension\",\n",
    "        coloraxis_colorbar=dict(title=\"Intensity\")\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "processed_df = process_data(df)\n",
    "fig = visualize_correlation(processed_df)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B-Senticnet for emotion analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argumentative Microtext Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_json(\"../data/dfMT2-PC_SA_CP_topicID_AduType.json\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 171 entries, 0 to 170\n",
      "Data columns (total 6 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   EDU        171 non-null    object\n",
      " 1   adu_type   171 non-null    object\n",
      " 2   topic_id   171 non-null    object\n",
      " 3   Relations  171 non-null    object\n",
      " 4   Label      171 non-null    object\n",
      " 5   STANCE     171 non-null    object\n",
      "dtypes: object(6)\n",
      "memory usage: 9.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pro_opp_RF(df):\n",
    "    df_exp = df.explode(['EDU', 'adu_type'])\n",
    "\n",
    "    X = df_exp['EDU']\n",
    "    y = df_exp['adu_type']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    y_pred_rf = clf.predict(X_test_tfidf)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "    class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "    print(f\"\\nRandom Forest Accuracy: {accuracy_rf}\")\n",
    "    print(f\"Random Forest Classification Report:\\n{class_report_rf}\")\n",
    "    \n",
    "\n",
    "\n",
    "    majority_classifier = DummyClassifier(strategy='most_frequent')\n",
    "    majority_classifier.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    y_pred_majority = majority_classifier.predict(X_test_tfidf)\n",
    "    accuracy_majority = accuracy_score(y_test, y_pred_majority)\n",
    "    class_report_majority = classification_report(y_test, y_pred_majority)\n",
    "\n",
    "    print(f\"\\nMajority Classifier Accuracy: {accuracy_majority}\")\n",
    "    print(f\"Majority Classifier Classification Report:\\n{class_report_majority}\")\n",
    "    \n",
    "\n",
    "    return accuracy_rf, class_report_rf, accuracy_majority, class_report_majority\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Accuracy: 0.8017241379310345\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.09      0.15        22\n",
      "           1       0.82      0.97      0.89        94\n",
      "\n",
      "    accuracy                           0.80       116\n",
      "   macro avg       0.61      0.53      0.52       116\n",
      "weighted avg       0.74      0.80      0.75       116\n",
      "\n",
      "\n",
      "Majority Classifier Accuracy: 0.8103448275862069\n",
      "Majority Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      1.00      0.90        94\n",
      "\n",
      "    accuracy                           0.81       116\n",
      "   macro avg       0.41      0.50      0.45       116\n",
      "weighted avg       0.66      0.81      0.73       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf, class_report_rf, accuracy_majority, class_report_majority = classify_pro_opp_RF(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_mismatched_rows(df):\n",
    "    mismatched_rows = df[df.apply(lambda row: len(row['EDU']) != len(row['adu_type']), axis=1)]\n",
    "    \n",
    "    #if not mismatched_rows.empty:\n",
    "    #    print(f\"Found {len(mismatched_rows)} rows with mismatched list lengths.\")\n",
    "    #    print(mismatched_rows)\n",
    "    \n",
    "    df = df[df.apply(lambda row: len(row['EDU']) == len(row['adu_type']), axis=1)]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_new = handle_mismatched_rows(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest Accuracy: 0.85\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.86      0.99      0.92       137\n",
      "\n",
      "    accuracy                           0.85       160\n",
      "   macro avg       0.43      0.50      0.46       160\n",
      "weighted avg       0.73      0.85      0.79       160\n",
      "\n",
      "\n",
      "Majority Classifier Accuracy: 0.85625\n",
      "Majority Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.86      1.00      0.92       137\n",
      "\n",
      "    accuracy                           0.86       160\n",
      "   macro avg       0.43      0.50      0.46       160\n",
      "weighted avg       0.73      0.86      0.79       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_rf_2, class_report_rf_2, accuracy_majority_2, class_report_majority_2 = classify_pro_opp_RF(df2_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def classify_pro_opp_SVM(df):\n",
    "    df = handle_mismatched_rows(df)\n",
    "    \n",
    "    df_exp = df.explode(['EDU', 'adu_type'])\n",
    "\n",
    "    X = df_exp['EDU']\n",
    "    y = df_exp['adu_type']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y) \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    clf = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    y_pred_svm = clf.predict(X_test_tfidf)\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "    print(f\"\\nSVM Accuracy: {accuracy_svm}\")\n",
    "    print(f\"SVM Classification Report:\\n{class_report_svm}\")\n",
    "\n",
    "    majority_classifier = DummyClassifier(strategy='most_frequent')\n",
    "    majority_classifier.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    y_pred_majority = majority_classifier.predict(X_test_tfidf)\n",
    "    accuracy_majority = accuracy_score(y_test, y_pred_majority)\n",
    "    class_report_majority = classification_report(y_test, y_pred_majority)\n",
    "\n",
    "    print(f\"\\nMajority Classifier Accuracy: {accuracy_majority}\")\n",
    "    print(f\"Majority Classifier Classification Report:\\n{class_report_majority}\")\n",
    "\n",
    "    return accuracy_svm, class_report_svm, accuracy_majority, class_report_majority\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy: 0.7672413793103449\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.32      0.34        22\n",
      "           1       0.85      0.87      0.86        94\n",
      "\n",
      "    accuracy                           0.77       116\n",
      "   macro avg       0.61      0.60      0.60       116\n",
      "weighted avg       0.75      0.77      0.76       116\n",
      "\n",
      "\n",
      "Majority Classifier Accuracy: 0.8103448275862069\n",
      "Majority Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      1.00      0.90        94\n",
      "\n",
      "    accuracy                           0.81       116\n",
      "   macro avg       0.41      0.50      0.45       116\n",
      "weighted avg       0.66      0.81      0.73       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm, class_report_svm, accuracy_majority, class_report_majority = classify_pro_opp_SVM(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy: 0.79375\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.26      0.27        23\n",
      "           1       0.88      0.88      0.88       137\n",
      "\n",
      "    accuracy                           0.79       160\n",
      "   macro avg       0.57      0.57      0.57       160\n",
      "weighted avg       0.79      0.79      0.79       160\n",
      "\n",
      "\n",
      "Majority Classifier Accuracy: 0.85625\n",
      "Majority Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.86      1.00      0.92       137\n",
      "\n",
      "    accuracy                           0.86       160\n",
      "   macro avg       0.43      0.50      0.46       160\n",
      "weighted avg       0.73      0.86      0.79       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_2, class_report_svm_2, accuracy_majority_2, class_report_majority_2 = classify_pro_opp_SVM(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD NRC values as features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pro_opp_SVM_NRC(df):\n",
    "    df = handle_mismatched_rows(df)\n",
    "    \n",
    "    df_exp = df.explode(['EDU', 'adu_type'])\n",
    "\n",
    "    X = df_exp['EDU']\n",
    "    y = df_exp['adu_type']\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)  \n",
    "    \n",
    "    nrc_features = X.apply(lambda text: calculate_nrc(text))\n",
    "    nrc_df = pd.DataFrame(nrc_features.tolist())  \n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_tfidf = vectorizer.fit_transform(X)\n",
    "    \n",
    "    X_combined = np.hstack((X_tfidf.toarray(), nrc_df.to_numpy()))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_combined, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "    clf = SVC(kernel='linear', class_weight='balanced', random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_svm = clf.predict(X_test)\n",
    "    accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "    class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "\n",
    "    print(f\"\\nSVM Accuracy: {accuracy_svm}\")\n",
    "    print(f\"SVM Classification Report:\\n{class_report_svm}\")\n",
    "\n",
    "    majority_classifier = DummyClassifier(strategy='most_frequent')\n",
    "    majority_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_majority = majority_classifier.predict(X_test)\n",
    "    accuracy_majority = accuracy_score(y_test, y_pred_majority)\n",
    "    class_report_majority = classification_report(y_test, y_pred_majority)\n",
    "\n",
    "    print(f\"\\nMajority Classifier Accuracy: {accuracy_majority}\")\n",
    "    print(f\"Majority Classifier Classification Report:\\n{class_report_majority}\")\n",
    "\n",
    "    return accuracy_svm, class_report_svm, accuracy_majority, class_report_majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy: 0.8103448275862069\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.32      0.39        22\n",
      "           1       0.85      0.93      0.89        94\n",
      "\n",
      "    accuracy                           0.81       116\n",
      "   macro avg       0.68      0.62      0.64       116\n",
      "weighted avg       0.79      0.81      0.79       116\n",
      "\n",
      "\n",
      "Majority Classifier Accuracy: 0.8103448275862069\n",
      "Majority Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        22\n",
      "           1       0.81      1.00      0.90        94\n",
      "\n",
      "    accuracy                           0.81       116\n",
      "   macro avg       0.41      0.50      0.45       116\n",
      "weighted avg       0.66      0.81      0.73       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_nrc, class_report_svm_nrc, accuracy_majority_nrc, class_report_majority_nrc = classify_pro_opp_SVM_NRC(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Accuracy: 0.81875\n",
      "SVM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.26      0.29        23\n",
      "           1       0.88      0.91      0.90       137\n",
      "\n",
      "    accuracy                           0.82       160\n",
      "   macro avg       0.61      0.59      0.59       160\n",
      "weighted avg       0.80      0.82      0.81       160\n",
      "\n",
      "\n",
      "Majority Classifier Accuracy: 0.85625\n",
      "Majority Classifier Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        23\n",
      "           1       0.86      1.00      0.92       137\n",
      "\n",
      "    accuracy                           0.86       160\n",
      "   macro avg       0.43      0.50      0.46       160\n",
      "weighted avg       0.73      0.86      0.79       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "h:\\moha\\NLP\\AM\\SA\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_svm_nrc2, class_report_svm_nrc2, accuracy_majority_nrc2, class_report_majority_nrc2 = classify_pro_opp_SVM_NRC(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
